{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d688bef1-545c-412e-b64d-47ce4a52363c",
   "metadata": {},
   "source": [
    "# init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fc3fb94-a965-4f94-8fc4-acab484eb4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install paddleocr, face_recognition, google-genai, pypinyin, json_repair\n",
    "\n",
    "# # install one of below\n",
    "# !pip install paddlepaddle    # to use cpu\n",
    "# !pip install paddlepaddle-gpu    # to use Nvidia gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a5f8b07-d064-4dc3-b9d3-edae1c4abe1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yoyo.wu.int/Documents/Meme/venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/Users/yoyo.wu.int/Documents/Meme/venv/lib/python3.13/site-packages/face_recognition_models/__init__.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import resource_filename\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "import json\n",
    "import pickle\n",
    "import pprint\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from json_repair import repair_json \n",
    "from zoneinfo import ZoneInfo\n",
    "from tqdm.auto import tqdm\n",
    "from getpass import getpass\n",
    "from pathlib import Path\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from PIL import Image, ImageDraw\n",
    "from pypinyin import pinyin, Style\n",
    "from paddleocr import PaddleOCR\n",
    "\n",
    "import face_recognition\n",
    "\n",
    "from google import genai\n",
    "from google.genai import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2dea0330-5c94-4ffd-90c3-8aa62aa048e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "GEMINI_API_KEY = getpass('api key: ')\n",
    "client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80588dff-f071-46df-93c6-f9f25bd14716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset paths\n",
    "meme_dir_path = '../datasets/test_dir_real/'\n",
    "\n",
    "# face recg params\n",
    "RECG_MODEL_PATH = \"../models/trained_svm_model_real25.pkl\"\n",
    "RECG_THRESHOLD = 0.1\n",
    "\n",
    "# ocr params\n",
    "OCR_THRESHOLD = 0.9\n",
    "ocr_cache_path = \"caches/ocr_cache/\"\n",
    "\n",
    "# llm params\n",
    "output_dir_path = 'results'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d462f84a-3421-403a-ba80-c7218e2c4e17",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "493c3fef-7643-470b-abb7-4b4a874aa5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id_names_from_path(meme_path: str):\n",
    "    \"\"\" \n",
    "    given a img path, return the meme id and politician name. \n",
    "    e.g. input: './test/004_lai_qing_de.jpg', returns '004' and 'lai_qing_de'.\n",
    "    \"\"\"\n",
    "    # get stem\n",
    "    stem = Path(meme_path).stem\n",
    "    parts = stem.split('_')\n",
    "    meme_num = parts[0]\n",
    "    others = '_'.join(parts[1:])\n",
    "\n",
    "    # multiple names\n",
    "    if '&' in others:\n",
    "        names = others.split('&')\n",
    "    else:\n",
    "        names = [others]\n",
    "    \n",
    "    return meme_num, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60306cf1-7d1e-408b-8e02-d63ee60d99bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "entries = os.listdir(meme_dir_path)\n",
    "meme_paths = []\n",
    "for entry in entries:\n",
    "    if entry.endswith(('.jpg', '.jpeg', '.png')):\n",
    "        meme_path = meme_dir_path + entry\n",
    "        meme_paths.append(meme_path)\n",
    "print(len(meme_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a0f6efd-1db4-4370-9567-ec3d95a5e7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lst = []\n",
    "for meme_path in meme_paths:\n",
    "    meme_num, meme_names = extract_id_names_from_path(meme_path)\n",
    "    data_lst.append({\n",
    "        'meme_num': meme_num,\n",
    "        'meme_names': meme_names,\n",
    "        'meme_path': meme_path\n",
    "    })\n",
    "data_df = pd.DataFrame(data_lst)\n",
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e02fba9d-b840-41cf-a4bf-8c5546d67c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meme_num</th>\n",
       "      <th>meme_names</th>\n",
       "      <th>meme_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300</td>\n",
       "      <td>[lai_qing_de]</td>\n",
       "      <td>datasets/quick_test/300_lai_qing_de.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  meme_num     meme_names                                meme_path\n",
       "0      300  [lai_qing_de]  datasets/quick_test/300_lai_qing_de.png"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a347f484-cc0c-45b8-b380-33762dad5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs_to_predict = data_df['meme_path']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8813d8c7-03c1-4909-b1ba-1865e66cc21e",
   "metadata": {},
   "source": [
    "# get candidate list w/ face recg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f647db1d-3394-439f-b46b-74c466088895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_names(model, image_path: str, prediction_threshold: float):\n",
    "    test_image = face_recognition.load_image_file(image_path)\n",
    "\n",
    "    # find faces\n",
    "    face_locations = face_recognition.face_locations(test_image)\n",
    "    num_faces = len(face_locations)\n",
    "\n",
    "    face_recg_pred = []\n",
    "\n",
    "    if not face_locations:\n",
    "        return face_recg_pred\n",
    "\n",
    "    # encode faces\n",
    "    test_image_encodings = face_recognition.face_encodings(\n",
    "        test_image, known_face_locations=face_locations, model=\"large\"\n",
    "    )\n",
    "\n",
    "    if np.isnan(test_image_encodings).any():\n",
    "        print(f\"Warning: Skipping {image_path}. Encoding contains NaN.\")\n",
    "        return face_recg_pred\n",
    "\n",
    "    # predict\n",
    "    for index, test_image_enc in enumerate(test_image_encodings, start=1):\n",
    "        probabilities = model.predict_proba([test_image_enc])[0]\n",
    "        entries = [\n",
    "            {\n",
    "                \"face_index\": index,\n",
    "                \"name\": name,\n",
    "                \"prob\": float(f\"{prob:.4f}\"),\n",
    "            }\n",
    "            for name, prob in zip(model.classes_, probabilities)\n",
    "        ]\n",
    "\n",
    "        sorted_entries = sorted(entries, key=lambda item: item[\"prob\"], reverse=True)\n",
    "        for entry in sorted_entries:\n",
    "            if entry[\"prob\"] >= prediction_threshold:\n",
    "                face_recg_pred.append(entry)\n",
    "    return face_recg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfb8c075-f77e-426b-a924-1a084c2dfc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face recognition model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "try:\n",
    "    with open(RECG_MODEL_PATH, \"rb\") as model_path:\n",
    "        model = pickle.load(model_path)\n",
    "        print('Face recognition model loaded successfully!')\n",
    "except Exception as e:\n",
    "    print(f\"Error loading recognition model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f98b0ac1-3142-402e-8e7e-e82a93aa91a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.11it/s]\n"
     ]
    }
   ],
   "source": [
    "# predict candidates\n",
    "face_recg_preds = []\n",
    "for img_path in tqdm(imgs_to_predict):\n",
    "    pred_res = predict_names(model, img_path, RECG_THRESHOLD)\n",
    "    candidates_lst = list(set([p['name'] for p in pred_res]))\n",
    "    face_recg_preds.append({\n",
    "        'meme_path': img_path,\n",
    "        'candidates': candidates_lst,\n",
    "        'cand_details': pred_res\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6622bc14-4825-498f-a978-331ff3ae9a87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join result back to data_df\n",
    "face_recg_df = pd.json_normalize(face_recg_preds)\n",
    "data_df = pd.merge(right=data_df, left=face_recg_df, on='meme_path', how='inner')\n",
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dad404a0-65a5-46ce-a97d-bf1ec03a183b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meme_path</th>\n",
       "      <th>candidates</th>\n",
       "      <th>cand_details</th>\n",
       "      <th>meme_num</th>\n",
       "      <th>meme_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/quick_test/300_lai_qing_de.png</td>\n",
       "      <td>[lai_qing_de]</td>\n",
       "      <td>[{'face_index': 1, 'name': 'lai_qing_de', 'pro...</td>\n",
       "      <td>300</td>\n",
       "      <td>[lai_qing_de]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 meme_path     candidates  \\\n",
       "0  datasets/quick_test/300_lai_qing_de.png  [lai_qing_de]   \n",
       "\n",
       "                                        cand_details meme_num     meme_names  \n",
       "0  [{'face_index': 1, 'name': 'lai_qing_de', 'pro...      300  [lai_qing_de]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df4db38-415e-48a7-9c03-8339a792a205",
   "metadata": {},
   "source": [
    "# get ocr text w/ paddleocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b403ef16-513c-44e0-9a47-dee328bb1440",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ocr_text(img_path, threshold):\n",
    "    # init\n",
    "    ocr = PaddleOCR(\n",
    "        use_doc_orientation_classify=False,\n",
    "        use_doc_unwarping=False,\n",
    "        use_textline_orientation=False\n",
    "    )\n",
    "    \n",
    "    # ocr\n",
    "    result = ocr.predict(input=img_path)\n",
    "    rec_texts = result[0]['rec_texts']\n",
    "    rec_probs = result[0]['rec_scores']\n",
    "    \n",
    "    # store res\n",
    "    ocr_res = []\n",
    "    for i, prob in enumerate(rec_probs):\n",
    "        if prob >= threshold:\n",
    "            ocr_res.append({\n",
    "                \"text\": rec_texts[i],\n",
    "                \"prob\": float(f\"{prob:.4f}\")\n",
    "            })\n",
    "    return ocr_res\n",
    "\n",
    "def get_ocr_text_cached(img_path, threshold, cache_dir):\n",
    "    \"\"\"Return cached OCR results when available.\"\"\"\n",
    "    from pathlib import Path\n",
    "    import hashlib\n",
    "    import json\n",
    "\n",
    "    cache_dir_path = Path(cache_dir)\n",
    "    cache_dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    key_source = f\"{Path(img_path).resolve()}|{threshold}\"\n",
    "    cache_name = hashlib.md5(key_source.encode(\"utf-8\")).hexdigest()\n",
    "    cache_file = cache_dir_path / f\"{cache_name}.json\"\n",
    "\n",
    "    if cache_file.exists():\n",
    "        with cache_file.open(\"r\", encoding=\"utf-8\") as cache_handle:\n",
    "            cache_res = json.load(cache_handle)\n",
    "            # filter with threshold\n",
    "            ocr_res = []\n",
    "            for i, pred in enumerate(cache_res):\n",
    "                if pred['prob'] >= threshold:\n",
    "                    ocr_res.append({\n",
    "                        \"text\": pred['text'],\n",
    "                        \"prob\": pred['prob']\n",
    "                    })\n",
    "            return ocr_res\n",
    "\n",
    "    ocr_res = get_ocr_text(img_path, threshold)\n",
    "\n",
    "    with cache_file.open(\"w\", encoding=\"utf-8\") as cache_handle:\n",
    "        json.dump(ocr_res, cache_handle, ensure_ascii=False)\n",
    "\n",
    "    print('Loaded OCR results from cache.')\n",
    "    return ocr_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44f71868-fbfc-416b-9f4d-9e0f7c31d2ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]/Users/yoyo.wu.int/Documents/Meme/venv/lib/python3.13/site-packages/paddle/utils/cpp_extension/extension_utils.py:718: UserWarning: No ccache found. Please be aware that recompiling all source files may be required. You can download and install ccache from: https://github.com/ccache/ccache/blob/master/doc/INSTALL.md\n",
      "  warnings.warn(warning_message)\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_det', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/Users/yoyo.wu.int/.paddlex/official_models/PP-OCRv5_server_det`.\u001b[0m\n",
      "\u001b[32mCreating model: ('PP-OCRv5_server_rec', None)\u001b[0m\n",
      "\u001b[32mModel files already exist. Using cached files. To redownload, please delete the directory manually: `/Users/yoyo.wu.int/.paddlex/official_models/PP-OCRv5_server_rec`.\u001b[0m\n",
      "100%|██████████| 1/1 [00:12<00:00, 12.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded OCR results from cache.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get ocr texts\n",
    "ocr_preds = []\n",
    "for img_path in tqdm(imgs_to_predict):\n",
    "    ocr_pred = get_ocr_text_cached(img_path, OCR_THRESHOLD, ocr_cache_path)\n",
    "    ocr_texts = list(set([p['text'] for p in ocr_pred]))\n",
    "    ocr_probs = [p['prob'] for p in ocr_pred]\n",
    "    \n",
    "    ocr_preds.append({\n",
    "            'meme_path': img_path,\n",
    "            'ocr_texts': ocr_texts,\n",
    "            'ocr_details': ocr_pred\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd23ed47-c684-4561-b444-de979086d263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join result back to data_df\n",
    "ocr_df = pd.json_normalize(ocr_preds)\n",
    "data_df = pd.merge(left=data_df, right=ocr_df, on='meme_path', how='inner')\n",
    "len(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da03d590-63d5-4cc3-a4e2-7b065c5528b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meme_path</th>\n",
       "      <th>candidates</th>\n",
       "      <th>cand_details</th>\n",
       "      <th>meme_num</th>\n",
       "      <th>meme_names</th>\n",
       "      <th>ocr_texts</th>\n",
       "      <th>ocr_details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets/quick_test/300_lai_qing_de.png</td>\n",
       "      <td>[lai_qing_de]</td>\n",
       "      <td>[{'face_index': 1, 'name': 'lai_qing_de', 'pro...</td>\n",
       "      <td>300</td>\n",
       "      <td>[lai_qing_de]</td>\n",
       "      <td>[早安！, 心想事成！]</td>\n",
       "      <td>[{'text': '早安！', 'prob': 0.987}, {'text': '心想事...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 meme_path     candidates  \\\n",
       "0  datasets/quick_test/300_lai_qing_de.png  [lai_qing_de]   \n",
       "\n",
       "                                        cand_details meme_num     meme_names  \\\n",
       "0  [{'face_index': 1, 'name': 'lai_qing_de', 'pro...      300  [lai_qing_de]   \n",
       "\n",
       "      ocr_texts                                        ocr_details  \n",
       "0  [早安！, 心想事成！]  [{'text': '早安！', 'prob': 0.987}, {'text': '心想事...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee000023-01c1-4361-a9d8-8a7558696a64",
   "metadata": {},
   "source": [
    "# get final prediction and explanation w/ gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cedd057b-afb9-4b1e-9a5b-d3ad7f937d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "你是一位專精於臺灣政治迷因的分析專家，擅長解讀圖片中的視覺隱喻、政治反諷及時事梗。\n",
    "請根據提供的圖片資訊、OCR 文字及參考名單，完成以下分析任務。\n",
    "\n",
    "# 任務說明\n",
    "1. **人物識別**：判斷迷因圖中是否出現（視覺人臉）或文字提及（OCR 內容）`politician_list` 中的政治人物。\n",
    "2. **內容解讀**：以繁體中文撰寫一句話，精簡說明迷因內容（包含諷刺議題、政治背景或人物行為）。\n",
    "\n",
    "# 輸入資料\n",
    "- **meme_texts**（OCR 文字）：{texts}\n",
    "- **possible_names**（參考線索）：{names} （註：此為人臉辨識模型的初步結果，準確度高但可能包含列表外的人物，請以此為重要線索並搭配 politician_list 過濾）\n",
    "- **politician_list**（允許的候選名單）：\n",
    "  [賴清德, 曹興誠, 柯建銘, 林智堅, 郭昱晴 (萬老師), 陳其邁, 邱議瑩, \n",
    "   王義川, 陳吉仲, 沈伯洋, 吳崢, 李進勇, 林楚茵, 呂建德, 林俊憲, 賴品妤, \n",
    "   吳思瑤, 李俊俋, 蔡英文, 吳靜怡, 黃捷, 蔡其昌, 吳沛憶, 劉世芳, 王定宇, 卓榮泰, 黃偉哲]\n",
    "\n",
    "# 輸出規則 (嚴格遵守)\n",
    "\n",
    "## 1. pred_names (List[str])\n",
    "- **封閉選項**：結果**必須完全來自** `politician_list`。絕對不可自行創造、翻譯或使用列表以外的名字。\n",
    "- **判斷邏輯**：\n",
    "    - 請綜合考量 `possible_names` (人臉線索) 與 `meme_texts` (文字線索)。\n",
    "    - 若 `possible_names` 中的名字也在 `politician_list` 中，請優先納入。\n",
    "    - 若圖中人物有綽號（例如 OCR 出現「柯P」、「小英」），請自動對應回 `politician_list` 中的本名（如：柯文哲、蔡英文）。\n",
    "- **空值處理**：若迷因中未出現或提及名單內的任何人物，請回傳空列表 `[]`（不要強行預測）。\n",
    "\n",
    "## 2. reason (str)\n",
    "- **單一句子**：必須是語意完整的一句話。\n",
    "- **內容焦點**：請指出「誰」在「什麼議題」上被「如何描繪/諷刺」。\n",
    "- **語言**：繁體中文。\n",
    "\n",
    "## 3. 格式限制\n",
    "- 僅輸出標準 JSON 格式，不要包含 Markdown 標記（如 ```json ... ```）或任何額外說明的文字。\n",
    "\n",
    "# 輸出範例\n",
    "{{\n",
    "  \"pred_names\": [\"林智堅\", \"蔡英文\"],\n",
    "  \"reason\": \"此圖諷刺林智堅在論文案爭議中，獲得黨內大力的支持與背書。\"\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e39aa85d-f5bd-419e-a8da-7c6f4204c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_gemini(candidates, ocr_texts, meme_img_bytes, data):\n",
    "    \n",
    "    # format prompt\n",
    "    prompt = PROMPT.format(\n",
    "        names=candidates,\n",
    "        texts=ocr_texts\n",
    "    )\n",
    "\n",
    "    # choose img file type\n",
    "    suffix = Path(data['meme_path']).suffix.lower()\n",
    "    if suffix in ('.jpg', '.jpeg'):\n",
    "      image_mime = 'image/jpeg'\n",
    "    elif suffix == '.png':\n",
    "      image_mime = 'image/png'\n",
    "    else:\n",
    "      raise('Error: Only supports jpg, jpeg, and png.')\n",
    "\n",
    "    # call gemini\n",
    "    response = client.models.generate_content(\n",
    "        model='gemini-2.5-flash',\n",
    "        contents=[\n",
    "          types.Part.from_bytes(\n",
    "            data=meme_img_bytes,\n",
    "            mime_type=image_mime,\n",
    "          ),\n",
    "          prompt\n",
    "        ]\n",
    "      )\n",
    "\n",
    "    # process result\n",
    "    cleaned_res = response.text.replace(\"```json\", \"\").replace(\"```\", \"\").replace(\"\\n\", \"\")\n",
    "    if len(cleaned_res) > 0:\n",
    "      res = json.loads(cleaned_res)\n",
    "      translated_names = [get_pinyin(name) for name in res['pred_names']]\n",
    "      res['pred_names'] = translated_names\n",
    "    else:\n",
    "      res = {}\n",
    "      \n",
    "    return res\n",
    "\n",
    "def get_pinyin(chinese_text):\n",
    "    \"\"\"Convert Chinese text to pinyin\"\"\"\n",
    "    # Convert to pinyin and join with underscores\n",
    "    result = pinyin(chinese_text, style=Style.NORMAL)\n",
    "    return '_'.join([''.join(p) for p in result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a1fc6c3-8e0c-47fc-87a1-dd3c518e7ab6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gemini prediction: 100%|██████████| 1/1 [00:14<00:00, 14.26s/it]\n"
     ]
    }
   ],
   "source": [
    "date_time = datetime.datetime.now(ZoneInfo('Asia/Taipei')) \n",
    "timestamp = date_time.strftime(\"%Y-%m-%d_%H-%M-%S\") \n",
    "output_path = f'{output_dir_path}/{timestamp}.jsonl'\n",
    "os.makedirs(output_dir_path, exist_ok=True)\n",
    "\n",
    "for index, row in tqdm(data_df.iterrows(), total=len(data_df), desc='Gemini prediction'):\n",
    "    \n",
    "    sleep_count = 0\n",
    "    data = row.to_dict()\n",
    "    try:\n",
    "        # load meme img\n",
    "        with open(data['meme_path'], 'rb') as f:\n",
    "            meme_img_bytes = f.read()\n",
    "    \n",
    "        # candidates\n",
    "        candidates = data['candidates']\n",
    "            \n",
    "        # ocr\n",
    "        ocr_texts = data['ocr_texts']\n",
    "    \n",
    "        # call gemini\n",
    "        if sleep_count >= 10:\n",
    "            time.sleep(3)\n",
    "            sleep_count = 0\n",
    "            \n",
    "        try:\n",
    "            # attempt 1\n",
    "            res = call_gemini(candidates, ocr_texts, meme_img_bytes, data)\n",
    "            data['llm_pred_names'] = res['pred_names']\n",
    "            data['llm_reason'] = res['reason']\n",
    "        except Exception as e:\n",
    "            print(f'error1: {e}')\n",
    "            # attempt 2\n",
    "            try:\n",
    "                res = call_gemini(candidates, ocr_texts, meme_img_bytes, data)\n",
    "                data['llm_pred_names'] = res['pred_names']\n",
    "                data['llm_reason'] = res['reason']\n",
    "            except Exception as e:\n",
    "                print(f'error2: {e}')\n",
    "                continue\n",
    "    \n",
    "        # store result to cache (to prevent crash)\n",
    "        with open(output_path, 'a') as f:\n",
    "            json_line = json.dumps(data) \n",
    "            f.write(json_line + '\\n')\n",
    "        sleep_count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f'error3: {e}')\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456b5619-2798-4a35-9ab2-a5c4c80a9254",
   "metadata": {},
   "source": [
    "# final result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "990e3dfb-fa1e-4b16-a359-7fda260cc24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "def display_df_image(df, index, path_column='meme_path'):\n",
    "    \"\"\"Displays the image for a specific row index.\"\"\"\n",
    "    image_path = df.loc[index, path_column]\n",
    "    \n",
    "    try:\n",
    "        print(image_path)\n",
    "        display(Image(filename=image_path, width=300))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Image file not found at {image_path}\")\n",
    "\n",
    "def cal_acc(df, type_, filter_none=False):\n",
    "    # Work on a copy\n",
    "    working_df = df.copy()\n",
    "    none_count = 0\n",
    "\n",
    "    # 1. Handle Filtering\n",
    "    if filter_none:\n",
    "        if type_ == 'face_rec_hit' or type_ == 'face_rec_top':\n",
    "            # Check if cand_details is empty/None\n",
    "            empty_mask = working_df['cand_details'].apply(\n",
    "                lambda x: len(x) == 0 if isinstance(x, list) else True\n",
    "            )\n",
    "        else:\n",
    "            empty_mask = working_df['llm_pred_names'].apply(\n",
    "                lambda x: len(x) == 0 if isinstance(x, list) else True\n",
    "            )\n",
    "        none_count = empty_mask.sum()\n",
    "        working_df = working_df[~empty_mask]\n",
    "\n",
    "    # 2. Extract Predictions based on type\n",
    "    if type_ == 'face_rec_hit':\n",
    "        preds = working_df['candidates'].apply(set)\n",
    "        \n",
    "    elif type_ == 'face_rec_top':\n",
    "        # Logic: Group by face_index -> Take max prob -> Collect names\n",
    "        def get_top_per_face_index(details_list):\n",
    "            if not isinstance(details_list, list) or len(details_list) == 0:\n",
    "                return set()\n",
    "            \n",
    "            # Dictionary to track the best candidate for each face\n",
    "            # Key: face_index, Value: {'name': ..., 'prob': ...}\n",
    "            best_faces = {}\n",
    "            \n",
    "            for item in details_list:\n",
    "                f_idx = item.get('face_index')\n",
    "                prob = item.get('prob', 0)\n",
    "                \n",
    "                # If we haven't seen this face_index, or if this prob is higher than current best\n",
    "                if f_idx not in best_faces or prob > best_faces[f_idx]['prob']:\n",
    "                    best_faces[f_idx] = item\n",
    "            \n",
    "            # Extract the names of the winners for each face index\n",
    "            return {v['name'] for v in best_faces.values()}\n",
    "\n",
    "        preds = working_df['cand_details'].apply(get_top_per_face_index)\n",
    "        \n",
    "    elif type_ == 'llm':\n",
    "        preds = working_df['llm_pred_names'].apply(\n",
    "            lambda x: set(x) if isinstance(x, list) else set()\n",
    "        )\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Invalid type_: {type_}\")\n",
    "\n",
    "    # 3. Calculate Counts\n",
    "    gts = working_df['meme_names'].apply(set)\n",
    "\n",
    "    # TP Count: Intersection of Predicted Names and Ground Truth Names\n",
    "    tp_count = sum(len(p.intersection(g)) for p, g in zip(preds, gts))\n",
    "\n",
    "    # True Count: Total ground truth labels\n",
    "    true_count = working_df['meme_names'].apply(len).sum()\n",
    "\n",
    "    # 4. Calculate Accuracy\n",
    "    acc = tp_count / true_count if true_count > 0 else 0.0\n",
    "\n",
    "    print(f'acc: {tp_count}/{true_count} = {acc:.4f}')\n",
    "    \n",
    "    if filter_none and none_count > 0:\n",
    "        print(f'none count: {none_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b9b5473-65d7-43b9-8b31-50b0ba409e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb9e98a9-67da-48ec-ab64-0e519d979421",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "165"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load result back\n",
    "timestamp = '2025-11-28_19-40-31'\n",
    "res = []\n",
    "with open(f'{output_dir_path}/{timestamp}.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        res.append(data)\n",
    "        \n",
    "res_df = pd.DataFrame(res)\n",
    "len(res_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3dcd256-ff9e-452e-9d05-bbbc25a1313f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 120/167 = 0.7186\n"
     ]
    }
   ],
   "source": [
    "cal_acc(res_df, 'face_rec_top', filter_none=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23b81d9d-769d-47db-82f4-5d49f89b9d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 134/167 = 0.8024\n"
     ]
    }
   ],
   "source": [
    "cal_acc(res_df, 'face_rec_hit', filter_none=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6dfea61d-7e56-4f14-9751-d9c751e193bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 159/167 = 0.9521\n"
     ]
    }
   ],
   "source": [
    "cal_acc(res_df, 'llm', filter_none=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb0d11bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 159/166 = 0.9578\n",
      "none count: 1\n"
     ]
    }
   ],
   "source": [
    "cal_acc(res_df, 'llm', filter_none=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b76463",
   "metadata": {},
   "outputs": [],
   "source": [
    "none = 17\n",
    "correct = 146\n",
    "wrong = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "908300fa-ad4f-4924-ab45-c55dfddb9bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_colwidth', None)\n",
    "res_df_filtered = res_df[['meme_num', 'meme_names', 'candidates', 'llm_pred_names', 'llm_reason', 'meme_path', 'ocr_texts', 'cand_details', 'ocr_details']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63d476e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>meme_num</th>\n",
       "      <th>meme_names</th>\n",
       "      <th>candidates</th>\n",
       "      <th>llm_pred_names</th>\n",
       "      <th>llm_reason</th>\n",
       "      <th>meme_path</th>\n",
       "      <th>ocr_texts</th>\n",
       "      <th>cand_details</th>\n",
       "      <th>ocr_details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>001</td>\n",
       "      <td>[qiu_yi_ying]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>此圖以醫生形象搭配「有病記得看醫生」的文字，諷刺政治場域中不理性的言行或決策，暗示其需要反思...</td>\n",
       "      <td>datasets/test_dir_real/001_qiu_yi_ying.jpeg</td>\n",
       "      <td>[有病記得看醫生]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[{'text': '有病記得看醫生', 'prob': 0.9729}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    meme_num     meme_names candidates llm_pred_names  \\\n",
       "157      001  [qiu_yi_ying]         []             []   \n",
       "\n",
       "                                            llm_reason  \\\n",
       "157  此圖以醫生形象搭配「有病記得看醫生」的文字，諷刺政治場域中不理性的言行或決策，暗示其需要反思...   \n",
       "\n",
       "                                       meme_path  ocr_texts cand_details  \\\n",
       "157  datasets/test_dir_real/001_qiu_yi_ying.jpeg  [有病記得看醫生]           []   \n",
       "\n",
       "                               ocr_details  \n",
       "157  [{'text': '有病記得看醫生', 'prob': 0.9729}]  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df_filtered[res_df_filtered['llm_pred_names'].apply(lambda x: len(x) == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "163e5423-ef06-48d1-aaa5-c1406f088bd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i in range(len(res_df)):\n",
    "#     display_df_image(res_df, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c168da89-bf91-454a-97e5-d51fb083a701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
